{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "uxV_9DmUg6lM",
        "outputId": "88a83499-a650-4cfd-fed4-d0a2c39a35b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "--- Scraping the latest launch data (pretty-printed) ---\n",
            "Error fetching latest launch data: 404 Client Error: Not Found for url: https://api.spacexdata.com/v3/launches/latest?pretty=true\n",
            "\n",
            "--- Scraping all launch data (handling pagination) ---\n",
            "Fetching launches with offset: 0\n",
            "Fetching launches with offset: 100\n",
            "Fetching launches with offset: 200\n",
            "No more launches to fetch. All data scraped.\n",
            "\n",
            "Successfully scraped 111 launches.\n",
            "Data saved to spacex_launches_data.json\n",
            "\n",
            "First 5 scraped launches:\n",
            "  Launch 1: Mission Name: FalconSat, Flight Number: 1\n",
            "  Launch 2: Mission Name: DemoSat, Flight Number: 2\n",
            "  Launch 3: Mission Name: Trailblazer, Flight Number: 3\n",
            "  Launch 4: Mission Name: RatSat, Flight Number: 4\n",
            "  Launch 5: Mission Name: RazakSat, Flight Number: 5\n",
            "\n",
            "--- Example: Fetching upcoming capsules with filters ---\n",
            "[\n",
            "  {\n",
            "    \"capsule_serial\": \"C202\",\n",
            "    \"status\": \"active\",\n",
            "    \"original_launch\": null\n",
            "  },\n",
            "  {\n",
            "    \"capsule_serial\": \"C203\",\n",
            "    \"status\": \"active\",\n",
            "    \"original_launch\": null\n",
            "  },\n",
            "  {\n",
            "    \"capsule_serial\": \"C204\",\n",
            "    \"status\": \"active\",\n",
            "    \"original_launch\": null\n",
            "  }\n",
            "]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1724c58a-0d4b-4e61-8243-ea3cf14f5c8e\", \"spacex_launches_data.json\", 582943)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- Step 1: Install necessary libraries (if not already installed in Colab) ---\n",
        "# The 'requests' library is usually pre-installed in Colab, but it's good practice to include this.\n",
        "# Run this cell once if you encounter a ModuleNotFoundError for 'requests'.\n",
        "!pip install requests\n",
        "\n",
        "# --- Step 2: Import libraries ---\n",
        "import requests\n",
        "import json\n",
        "import time # Import time for potential delays to respect API rate limits\n",
        "\n",
        "# --- Step 3: Define the scraping functions ---\n",
        "\n",
        "def get_spacex_data(endpoint=\"launches\", version=\"v3\", limit=None, offset=None, filters=None, pretty=False):\n",
        "    \"\"\"\n",
        "    Fetches data from the SpaceX API.\n",
        "\n",
        "    Args:\n",
        "        endpoint (str): The API endpoint (e.g., \"launches\", \"capsules\").\n",
        "        version (str): The API version (e.g., \"v3\").\n",
        "        limit (int, optional): Limits the number of results returned.\n",
        "        offset (int, optional): Offsets or skips results from the beginning.\n",
        "        filters (list, optional): A list of fields to include in the response (JSON field masking).\n",
        "                                  Example: [\"flight_number\", \"mission_name\", \"rocket/rocket_name\"]\n",
        "        pretty (bool, optional): If True, pretty-prints the JSON response.\n",
        "\n",
        "    Returns:\n",
        "        list or dict: The JSON data from the API.\n",
        "    \"\"\"\n",
        "    base_url = f\"https://api.spacexdata.com/{version}\"\n",
        "    url = f\"{base_url}/{endpoint}\"\n",
        "\n",
        "    params = {}\n",
        "    if limit is not None:\n",
        "        params['limit'] = limit\n",
        "    if offset is not None:\n",
        "        params['offset'] = offset\n",
        "    if filters:\n",
        "        params['filter'] = ','.join(filters)\n",
        "    if pretty:\n",
        "        params['pretty'] = 'true'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def scrape_all_launches(version=\"v3\"):\n",
        "    \"\"\"\n",
        "    Scrapes all launch data from the SpaceX API, handling pagination.\n",
        "\n",
        "    Args:\n",
        "        version (str): The API version (e.g., \"v3\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing all launch data.\n",
        "    \"\"\"\n",
        "    all_launches = []\n",
        "    offset = 0\n",
        "    limit = 100  # You can adjust this limit based on API limits and performance\n",
        "\n",
        "    while True:\n",
        "        print(f\"Fetching launches with offset: {offset}\")\n",
        "        launches_batch = get_spacex_data(endpoint=\"launches\", version=version, limit=limit, offset=offset)\n",
        "\n",
        "        if launches_batch is None:\n",
        "            print(\"Failed to retrieve data for this batch. Stopping.\")\n",
        "            break\n",
        "\n",
        "        if not launches_batch:\n",
        "            # No more data to fetch (empty list returned)\n",
        "            print(\"No more launches to fetch. All data scraped.\")\n",
        "            break\n",
        "\n",
        "        all_launches.extend(launches_batch)\n",
        "        offset += limit\n",
        "\n",
        "        # Optional: Add a small delay to avoid hitting API rate limits too aggressively\n",
        "        # time.sleep(0.1) # Sleep for 100 milliseconds between requests if needed\n",
        "\n",
        "    return all_launches\n",
        "\n",
        "# --- Step 4: Execute the scraping and save data ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Scraping the latest launch data (pretty-printed) ---\")\n",
        "    latest_launch_url = \"https://api.spacexdata.com/v3/launches/latest\"\n",
        "    try:\n",
        "        response_latest = requests.get(latest_launch_url, params={'pretty': 'true'})\n",
        "        response_latest.raise_for_status()\n",
        "        latest_launch_data = response_latest.json()\n",
        "        print(json.dumps(latest_launch_data, indent=2))\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching latest launch data: {e}\")\n",
        "\n",
        "    print(\"\\n--- Scraping all launch data (handling pagination) ---\")\n",
        "    all_spacex_launches = scrape_all_launches(version=\"v3\")\n",
        "\n",
        "    if all_spacex_launches:\n",
        "        print(f\"\\nSuccessfully scraped {len(all_spacex_launches)} launches.\")\n",
        "        # Example of how to save the data to a JSON file in Colab's temporary storage\n",
        "        output_filename = \"spacex_launches_data.json\"\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(all_spacex_launches, f, indent=2)\n",
        "        print(f\"Data saved to {output_filename}\")\n",
        "\n",
        "        # You can now work with 'all_spacex_launches' which contains all the data\n",
        "        # For example, print the mission name and flight number of the first 5 launches:\n",
        "        print(\"\\nFirst 5 scraped launches:\")\n",
        "        for i, launch in enumerate(all_spacex_launches[:5]):\n",
        "            print(f\"  Launch {i+1}: Mission Name: {launch.get('mission_name')}, Flight Number: {launch.get('flight_number')}\")\n",
        "    else:\n",
        "        print(\"No launch data was scraped.\")\n",
        "\n",
        "    print(\"\\n--- Example: Fetching upcoming capsules with filters ---\")\n",
        "    upcoming_capsules_filters = [\"capsule_serial\", \"status\", \"original_launch\"]\n",
        "    upcoming_capsules_data = get_spacex_data(\n",
        "        endpoint=\"capsules/upcoming\",\n",
        "        version=\"v3\",\n",
        "        filters=upcoming_capsules_filters,\n",
        "        pretty=True\n",
        "    )\n",
        "    if upcoming_capsules_data:\n",
        "        print(json.dumps(upcoming_capsules_data, indent=2))\n",
        "    else:\n",
        "        print(\"Failed to fetch upcoming capsules data.\")\n",
        "\n",
        "# --- Step 5: (Optional) Download the saved file from Colab ---\n",
        "# Run this cell after the scraping is complete to download the generated JSON file\n",
        "from google.colab import files\n",
        "files.download(output_filename)"
      ]
    }
  ]
}