{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inrI-6Oy4A4Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4d_Bm8Ze4DiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "SpaceX Web Scraping (without API) for Google Colab\n",
        "Target: Wikipedia's \"List of Falcon 9 and Falcon Heavy launches\"\n",
        "\"\"\"\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "!pip install requests beautifulsoup4 pandas\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re # For regular expressions, if needed for parsing strings\n",
        "\n",
        "# For saving to Google Drive (optional)\n",
        "from google.colab import drive\n",
        "from IPython.display import display # For better DataFrame display\n",
        "\n",
        "def scrape_spacex_launch_data_from_wikipedia():\n",
        "    \"\"\"\n",
        "    Web scrapes SpaceX Falcon 9 and Falcon Heavy launch data from Wikipedia.\n",
        "    Note: This is highly dependent on Wikipedia's page structure and can break easily.\n",
        "    Returns a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # URL of the Wikipedia page\n",
        "    url = \"https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\"\n",
        "    print(f\"Attempting to scrape data from: {url}\")\n",
        "\n",
        "    try:\n",
        "        # Fetch the HTML content\n",
        "        response = requests.get(url, timeout=10) # Add a timeout\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        print(\"Successfully fetched Wikipedia page.\")\n",
        "\n",
        "        # Find the main table containing launch data\n",
        "        # Wikipedia tables often have specific classes or captions.\n",
        "        # We'll look for tables with 'wikitable' class.\n",
        "        # There might be multiple tables; we need to find the right one.\n",
        "        # The main launch table usually has a caption or is the largest.\n",
        "        tables = soup.find_all('table', class_='wikitable')\n",
        "\n",
        "        # Heuristic: The largest table or one with a specific caption.\n",
        "        # Let's find the one that is likely the main launch list.\n",
        "        # Look for the table that contains columns like 'Flight No.', 'Date', 'Launch site'\n",
        "        target_table = None\n",
        "        for table in tables:\n",
        "            # Check if headers contain key terms to identify the main launch table\n",
        "            headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
        "            if 'Flight No.' in headers and 'Launch date (UTC)' in headers and 'Launch site' in headers:\n",
        "                target_table = table\n",
        "                break\n",
        "\n",
        "        if not target_table:\n",
        "            print(\"Could not find the main launch data table on the page.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        print(\"Found the main launch data table. Parsing...\")\n",
        "\n",
        "        # Get table headers\n",
        "        headers = [th.get_text(strip=True) for th in target_table.find_all('th')]\n",
        "\n",
        "        # Prepare a list to hold processed launch records\n",
        "        launch_records = []\n",
        "\n",
        "        # Iterate through table rows (skip header row)\n",
        "        rows = target_table.find_all('tr')[1:] # Skip the first row (headers)\n",
        "\n",
        "        for i, row in enumerate(rows):\n",
        "            cols = [td.get_text(strip=True) for td in row.find_all('td')]\n",
        "\n",
        "            # Debugging: Print headers and first few cols to understand structure\n",
        "            # if i == 0:\n",
        "            #    print(\"Table Headers:\", headers)\n",
        "            #    print(\"First Row Cols:\", cols)\n",
        "            #    print(\"Number of Headers:\", len(headers))\n",
        "            #    print(\"Number of Cols in first row:\", len(cols))\n",
        "\n",
        "            # Ensure the number of columns matches (can be tricky with colspan/rowspan)\n",
        "            if len(cols) < len(headers) - 1: # -1 because some tables have initial index column\n",
        "                # print(f\"Skipping row {i} due to mismatched column count: {len(cols)} vs {len(headers)}\")\n",
        "                continue # Skip rows that don't match expected structure (e.g., notes, empty rows)\n",
        "\n",
        "            record = {}\n",
        "            # Map Wikipedia columns to requested columns\n",
        "            # This mapping needs to be adjusted if Wikipedia's table structure changes.\n",
        "\n",
        "            # Example mapping based on a typical Wikipedia launch table:\n",
        "            # Assume order: Flight No., Launch date (UTC), Vehicle, Launch site,\n",
        "            # Payload, Orbit, Customer, Outcome, Landing outcome (core), Core (landing),\n",
        "            # Payload (landing), Remarks/Notes\n",
        "\n",
        "            # Simplified mapping for common columns directly from td index\n",
        "            # This is fragile! A more robust way uses the 'headers' list to map.\n",
        "            # Let's try to map by header text if available.\n",
        "\n",
        "            # Create a dictionary of column index to header name\n",
        "            header_map = {h: idx for idx, h in enumerate(headers)}\n",
        "\n",
        "            # --- Direct Mappings from table ---\n",
        "            record['Flight No.'] = cols[header_map.get('Flight No.', 0)] if 'Flight No.' in header_map else None\n",
        "            record['FlightNumber'] = record['Flight No.'] # Same as Flight No.\n",
        "\n",
        "            # Date and Time\n",
        "            date_time_str = cols[header_map.get('Launch date (UTC)', 1)] if 'Launch date (UTC)' in header_map else None\n",
        "            if date_time_str:\n",
        "                # Example: \"1 May 2024\\n01:30\"\n",
        "                date_match = re.search(r'(\\d{1,2}\\s[A-Za-z]+\\s\\d{4})', date_time_str)\n",
        "                time_match = re.search(r'(\\d{2}:\\d{2})', date_time_str)\n",
        "                record['Date'] = date_match.group(1) if date_match else None\n",
        "                record['Time'] = time_match.group(1) if time_match else None\n",
        "            else:\n",
        "                record['Date'] = None\n",
        "                record['Time'] = None\n",
        "\n",
        "            record['Launch site'] = cols[header_map.get('Launch site', 3)] if 'Launch site' in header_map else None\n",
        "            record['LaunchSite'] = record['Launch site']\n",
        "\n",
        "            record['Payload'] = cols[header_map.get('Payload', 4)] if 'Payload' in header_map else None\n",
        "            record['Orbit'] = cols[header_map.get('Orbit', 5)] if 'Orbit' in header_map else None\n",
        "            record['Customer'] = cols[header_map.get('Customer', 6)] if 'Customer' in header_map else None\n",
        "\n",
        "            record['Outcome'] = cols[header_map.get('Outcome', 7)] if 'Outcome' in header_map else None\n",
        "            record['Launchoutcome'] = record['Outcome']\n",
        "\n",
        "            record['BoosterVersion'] = cols[header_map.get('Vehicle', 2)] if 'Vehicle' in header_map else None\n",
        "            record['Version Booster'] = record['BoosterVersion']\n",
        "\n",
        "            # Booster landing (from \"Landing outcome (core)\" or similar)\n",
        "            landing_outcome_core = cols[header_map.get('Landing outcome (core)', 8)] if 'Landing outcome (core)' in header_map else None\n",
        "            record['Booster landing'] = landing_outcome_core\n",
        "\n",
        "            # --- Columns very difficult or impossible to get reliably from table ---\n",
        "            record['PayloadMass'] = None # Often buried in notes or requires separate lookup\n",
        "            record['Longitude'] = None # Not in table, requires separate lookup for launch sites\n",
        "            record['Latitude'] = None  # Not in table, requires separate lookup for launch sites\n",
        "            record['Flights'] = None # Hard to get core-specific flight count from main table\n",
        "            record['GridFins'] = None # Not typically in this type of table\n",
        "            record['Reused'] = None # Can sometimes infer from 'Core' column, but not explicit for all\n",
        "            record['Legs'] = None # Not typically in this type of table\n",
        "            record['LandingPad'] = None # Usually listed with landing outcome, but formal name may vary\n",
        "            record['Block'] = None # Not typically in this type of table\n",
        "            record['ReusedCount'] = None # Not directly available from main table\n",
        "            record['Serial'] = None # Sometimes in 'Core' column, but not consistently parseable for all\n",
        "\n",
        "            # Attempt to extract 'Reused' and 'Serial' from 'Core' column if it exists and structured\n",
        "            # This is highly heuristic and may not work for all rows/table versions\n",
        "            if 'Core' in header_map and len(cols) > header_map['Core']:\n",
        "                core_info_str = cols[header_map['Core']]\n",
        "                if '—' in core_info_str or 'new' in core_info_str.lower():\n",
        "                    record['Reused'] = False\n",
        "                elif 'Refurbished' in core_info_str or 'reused' in core_info_str.lower():\n",
        "                    record['Reused'] = True\n",
        "\n",
        "                # Try to extract serial (e.g., B1049.10)\n",
        "                serial_match = re.search(r'(B\\d{4}\\.\\d+)', core_info_str)\n",
        "                if serial_match:\n",
        "                    record['Serial'] = serial_match.group(1)\n",
        "                else: # Try other patterns like just B10XX\n",
        "                    serial_match = re.search(r'(B\\d{4})', core_info_str)\n",
        "                    if serial_match:\n",
        "                        record['Serial'] = serial_match.group(1)\n",
        "\n",
        "            launch_records.append(record)\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"Processed {i + 1} rows...\")\n",
        "\n",
        "        print(f\"Finished parsing {len(launch_records)} launch records.\")\n",
        "        df = pd.DataFrame(launch_records)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"HTTP Error: {errh}\")\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        print(f\"Error Connecting: {errc}\")\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        print(f\"Timeout Error: {errt}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"An error occurred: {err}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during parsing: {e}\")\n",
        "\n",
        "    return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    spacex_df_scraped = scrape_spacex_launch_data_from_wikipedia()\n",
        "\n",
        "    if not spacex_df_scraped.empty:\n",
        "        print(\"\\nSpaceX Scraped Launch Data (first 5 rows):\")\n",
        "        display(spacex_df_scraped.head()) # Use display() for better Colab output\n",
        "\n",
        "        print(f\"\\nTotal launches scraped: {len(spacex_df_scraped)}\")\n",
        "        print(\"\\nAll columns available from scraping:\")\n",
        "        print(spacex_df_scraped.columns.tolist())\n",
        "\n",
        "        # --- Colab Specific: Saving the DataFrame ---\n",
        "\n",
        "        # Option 1: Save to a CSV file in the Colab temporary storage\n",
        "        csv_filename = \"spacex_scraped_launches.csv\"\n",
        "        spacex_df_scraped.to_csv(csv_filename, index=False)\n",
        "        print(f\"\\nData saved to {csv_filename} in Colab environment.\")\n",
        "        print(f\"You can download this file from the 'Files' tab (left sidebar) or using: from google.colab import files; files.download('{csv_filename}')\")\n",
        "\n",
        "        # Option 2: Save to Google Drive (persistent storage)\n",
        "        try:\n",
        "            print(\"\\nAttempting to mount Google Drive for persistent storage...\")\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            drive_path = '/content/drive/MyDrive/spacex_scraped_data/' # Create this folder in your Drive\n",
        "            import os\n",
        "            os.makedirs(drive_path, exist_ok=True)\n",
        "            drive_csv_path = os.path.join(drive_path, csv_filename)\n",
        "            spacex_df_scraped.to_csv(drive_csv_path, index=False)\n",
        "            print(f\"Data saved to Google Drive at: {drive_csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nCould not mount Google Drive or save to Drive: {e}\")\n",
        "            print(\"To save to Drive, you need to authenticate your Google account (follow prompts).\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve SpaceX launch data via web scraping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sA-_3RP4DrZ",
        "outputId": "9a1ae571-67cc-4709-9067-96313c9c8bf9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Attempting to scrape data from: https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n",
            "Successfully fetched Wikipedia page.\n",
            "Could not find the main launch data table on the page.\n",
            "Failed to retrieve SpaceX launch data via web scraping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "SpaceX Web Scraping (without API) for Google Colab\n",
        "Target: Wikipedia's \"List of Falcon 9 and Falcon Heavy launches\"\n",
        "\"\"\"\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "# !pip install requests beautifulsoup4 pandas # Already satisfied from output\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re # For regular expressions, if needed for parsing strings\n",
        "\n",
        "# For saving to Google Drive (optional)\n",
        "from google.colab import drive\n",
        "from IPython.display import display # For better DataFrame display\n",
        "\n",
        "def scrape_spacex_launch_data_from_wikipedia():\n",
        "    \"\"\"\n",
        "    Web scrapes SpaceX Falcon 9 and Falcon Heavy launch data from Wikipedia.\n",
        "    Note: This is highly dependent on Wikipedia's page structure and can break easily.\n",
        "    Returns a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    # URL of the Wikipedia page\n",
        "    url = \"https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\"\n",
        "    print(f\"Attempting to scrape data from: {url}\")\n",
        "\n",
        "    try:\n",
        "        # Fetch the HTML content\n",
        "        response = requests.get(url, timeout=10) # Add a timeout\n",
        "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        print(\"Successfully fetched Wikipedia page.\")\n",
        "\n",
        "        # Find the main table containing launch data\n",
        "        # Wikipedia tables often have specific classes or captions.\n",
        "        # We'll look for tables with 'wikitable' class.\n",
        "        tables = soup.find_all('table', class_='wikitable')\n",
        "\n",
        "        target_table = None\n",
        "        # We need to find the table that has specific headers relevant to launches.\n",
        "        # Let's be more flexible with header names that might have subtle differences\n",
        "        # or additional elements (like <sup> tags for references).\n",
        "\n",
        "        for table in tables:\n",
        "            # Get headers, stripping any reference superscripts or extra spaces\n",
        "            headers_raw = [th.get_text(strip=True) for th in table.find_all('th')]\n",
        "            # Clean headers by removing content within brackets, e.g., '[n]' for references\n",
        "            headers_cleaned = [re.sub(r'\\[.*?\\]', '', h).strip() for h in headers_raw]\n",
        "\n",
        "            # Check for core identifying headers\n",
        "            if 'Flight No.' in headers_cleaned and \\\n",
        "               'Launch date (UTC)' in headers_cleaned and \\\n",
        "               'Launch site' in headers_cleaned and \\\n",
        "               'Outcome' in headers_cleaned:\n",
        "                target_table = table\n",
        "                headers = headers_cleaned # Use the cleaned headers for mapping\n",
        "                print(\"Identified table by its core headers.\")\n",
        "                break\n",
        "\n",
        "        if not target_table:\n",
        "            # Fallback heuristic: Sometimes the most relevant table is the largest.\n",
        "            # Or, it might have a specific caption.\n",
        "            # Let's try to find tables with specific captions or a combination of elements.\n",
        "            # Or, loop through headers and print them to debug exactly what's being found.\n",
        "            print(\"Could not find the main launch data table using core headers. Trying alternative identification...\")\n",
        "\n",
        "            # This is a common way to identify the *first* main table\n",
        "            # after the summary/index tables.\n",
        "            # A common approach is to find the table with \"Flight No.\" as a header.\n",
        "            for table in tables:\n",
        "                headers_raw = [th.get_text(strip=True) for th in table.find_all('th')]\n",
        "                headers_cleaned = [re.sub(r'\\[.*?\\]', '', h).strip() for h in headers_raw]\n",
        "\n",
        "                if 'Flight No.' in headers_cleaned:\n",
        "                    target_table = table\n",
        "                    headers = headers_cleaned\n",
        "                    print(\"Identified table by 'Flight No.' header as a fallback.\")\n",
        "                    break\n",
        "\n",
        "            if not target_table:\n",
        "                print(\"Still could not find the main launch data table on the page.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "        print(\"Found the main launch data table. Parsing...\")\n",
        "\n",
        "        # At this point, 'headers' should contain the cleaned headers of 'target_table'\n",
        "\n",
        "        # Prepare a list to hold processed launch records\n",
        "        launch_records = []\n",
        "\n",
        "        # Iterate through table rows (skip header row)\n",
        "        rows = target_table.find_all('tr')[1:] # Skip the first row (headers)\n",
        "\n",
        "        for i, row in enumerate(rows):\n",
        "            cols = [td.get_text(strip=True) for td in row.find_all('td')]\n",
        "\n",
        "            # Handle rows that might be sub-headers or notes, by checking if they are too short\n",
        "            # A common issue is colspan/rowspan which makes len(cols) inconsistent.\n",
        "            # We'll skip rows that have significantly fewer columns than expected based on headers.\n",
        "            # A good minimum might be 5-6 core columns (Flight No, Date, Site, Payload, Outcome).\n",
        "            if len(cols) < 5:\n",
        "                continue\n",
        "\n",
        "            record = {}\n",
        "\n",
        "            # Create a dictionary of column header to its index for robust mapping\n",
        "            header_map = {h: idx for idx, h in enumerate(headers)}\n",
        "\n",
        "            # --- Direct Mappings from table using header_map ---\n",
        "            record['Flight No.'] = cols[header_map.get('Flight No.')] if 'Flight No.' in header_map and header_map.get('Flight No.') < len(cols) else None\n",
        "            record['FlightNumber'] = record['Flight No.']\n",
        "\n",
        "            # Date and Time\n",
        "            date_time_str = cols[header_map.get('Launch date (UTC)')] if 'Launch date (UTC)' in header_map and header_map.get('Launch date (UTC)') < len(cols) else None\n",
        "            if date_time_str:\n",
        "                # Remove reference brackets like [a] or [b]\n",
        "                date_time_str = re.sub(r'\\[.*?\\]', '', date_time_str).strip()\n",
        "                date_match = re.search(r'(\\d{1,2}\\s[A-Za-z]+\\s\\d{4})', date_time_str)\n",
        "                time_match = re.search(r'(\\d{2}:\\d{2})', date_time_str)\n",
        "                record['Date'] = date_match.group(1) if date_match else None\n",
        "                record['Time'] = time_match.group(1) if time_match else None\n",
        "            else:\n",
        "                record['Date'] = None\n",
        "                record['Time'] = None\n",
        "\n",
        "            record['Launch site'] = cols[header_map.get('Launch site')] if 'Launch site' in header_map and header_map.get('Launch site') < len(cols) else None\n",
        "            record['LaunchSite'] = record['Launch site']\n",
        "\n",
        "            record['Payload'] = cols[header_map.get('Payload')] if 'Payload' in header_map and header_map.get('Payload') < len(cols) else None\n",
        "            record['Orbit'] = cols[header_map.get('Orbit')] if 'Orbit' in header_map and header_map.get('Orbit') < len(cols) else None\n",
        "            record['Customer'] = cols[header_map.get('Customer')] if 'Customer' in header_map and header_map.get('Customer') < len(cols) else None\n",
        "\n",
        "            record['Outcome'] = cols[header_map.get('Outcome')] if 'Outcome' in header_map and header_map.get('Outcome') < len(cols) else None\n",
        "            record['Launchoutcome'] = record['Outcome']\n",
        "\n",
        "            record['BoosterVersion'] = cols[header_map.get('Vehicle')] if 'Vehicle' in header_map and header_map.get('Vehicle') < len(cols) else None\n",
        "            record['Version Booster'] = record['BoosterVersion']\n",
        "\n",
        "            # Booster landing (from \"Landing outcome (core)\" or similar)\n",
        "            landing_outcome_core = cols[header_map.get('Landing outcome (core)')] if 'Landing outcome (core)' in header_map and header_map.get('Landing outcome (core)') < len(cols) else None\n",
        "            record['Booster landing'] = landing_outcome_core\n",
        "\n",
        "            # --- Columns very difficult or impossible to get reliably from table ---\n",
        "            record['PayloadMass'] = None\n",
        "            record['Longitude'] = None\n",
        "            record['Latitude'] = None\n",
        "            record['Flights'] = None\n",
        "            record['GridFins'] = None\n",
        "            record['Reused'] = None\n",
        "            record['Legs'] = None\n",
        "            record['LandingPad'] = None\n",
        "            record['Block'] = None\n",
        "            record['ReusedCount'] = None\n",
        "            record['Serial'] = None\n",
        "\n",
        "            # Attempt to extract 'Reused' and 'Serial' from 'Core' column if it exists and structured\n",
        "            if 'Core' in header_map and header_map.get('Core') < len(cols):\n",
        "                core_info_str = cols[header_map['Core']]\n",
        "                if '—' in core_info_str or 'new' in core_info_str.lower():\n",
        "                    record['Reused'] = False\n",
        "                elif 'Refurbished' in core_info_str or 'reused' in core_info_str.lower():\n",
        "                    record['Reused'] = True\n",
        "\n",
        "                # Try to extract serial (e.g., B1049.10)\n",
        "                serial_match = re.search(r'(B\\d{4}(?:\\.\\d+)?)', core_info_str) # Made regex more flexible for .XX or no .\n",
        "                if serial_match:\n",
        "                    record['Serial'] = serial_match.group(1)\n",
        "\n",
        "            launch_records.append(record)\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                print(f\"Processed {i + 1} rows...\")\n",
        "\n",
        "        print(f\"Finished parsing {len(launch_records)} launch records.\")\n",
        "        df = pd.DataFrame(launch_records)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"HTTP Error: {errh}\")\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        print(f\"Error Connecting: {errc}\")\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        print(f\"Timeout Error: {errt}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"An error occurred: {err}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during parsing: {e}\")\n",
        "\n",
        "    return pd.DataFrame() # Return empty DataFrame on error\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    spacex_df_scraped = scrape_spacex_launch_data_from_wikipedia()\n",
        "\n",
        "    if not spacex_df_scraped.empty:\n",
        "        print(\"\\nSpaceX Scraped Launch Data (first 5 rows):\")\n",
        "        display(spacex_df_scraped.head())\n",
        "\n",
        "        print(f\"\\nTotal launches scraped: {len(spacex_df_scraped)}\")\n",
        "        print(\"\\nAll columns available from scraping:\")\n",
        "        print(spacex_df_scraped.columns.tolist())\n",
        "\n",
        "        # --- Colab Specific: Saving the DataFrame ---\n",
        "        csv_filename = \"spacex_scraped_launches.csv\"\n",
        "        spacex_df_scraped.to_csv(csv_filename, index=False)\n",
        "        print(f\"\\nData saved to {csv_filename} in Colab environment.\")\n",
        "        print(f\"You can download this file from the 'Files' tab (left sidebar) or using: from google.colab import files; files.download('{csv_filename}')\")\n",
        "\n",
        "        try:\n",
        "            print(\"\\nAttempting to mount Google Drive for persistent storage...\")\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            drive_path = '/content/drive/MyDrive/spacex_scraped_data/'\n",
        "            import os\n",
        "            os.makedirs(drive_path, exist_ok=True)\n",
        "            drive_csv_path = os.path.join(drive_path, csv_filename)\n",
        "            spacex_df_scraped.to_csv(drive_csv_path, index=False)\n",
        "            print(f\"Data saved to Google Drive at: {drive_csv_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nCould not mount Google Drive or save to Drive: {e}\")\n",
        "            print(\"To save to Drive, you need to authenticate your Google account (follow prompts).\")\n",
        "    else:\n",
        "        print(\"Failed to retrieve SpaceX launch data via web scraping.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "EaOJhsWR4YD3",
        "outputId": "b8099d51-c9b5-4455-c3e4-bd110d49cd12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to scrape data from: https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\n",
            "Successfully fetched Wikipedia page.\n",
            "Could not find the main launch data table using core headers. Trying alternative identification...\n",
            "Identified table by 'Flight No.' header as a fallback.\n",
            "Found the main launch data table. Parsing...\n",
            "Processed 50 rows...\n",
            "Processed 100 rows...\n",
            "Processed 150 rows...\n",
            "Finished parsing 98 launch records.\n",
            "\n",
            "SpaceX Scraped Launch Data (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  Flight No.               FlightNumber  Date  Time  \\\n",
              "0   January 3, 202314:56[17]   January 3, 202314:56[17]  None  None   \n",
              "1  January 10, 202304:50[23]  January 10, 202304:50[23]  None  None   \n",
              "2  January 15, 202322:56[29]  January 15, 202322:56[29]  None  None   \n",
              "3  January 18, 202312:24[33]  January 18, 202312:24[33]  None  None   \n",
              "4  January 19, 202315:43[39]  January 19, 202315:43[39]  None  None   \n",
              "\n",
              "  Launch site LaunchSite                Payload    Orbit Customer Outcome  \\\n",
              "0        None       None             Unknown[j]  Various  Success    None   \n",
              "1        None       None   6,000 kg (13,000 lb)   OneWeb  Success    None   \n",
              "2        None       None   ~3,750 kg (8,270 lb)     USSF  Success    None   \n",
              "3        None       None    4,352 kg (9,595 lb)     USSF  Success    None   \n",
              "4        None       None  15,000 kg (33,000 lb)   SpaceX  Success    None   \n",
              "\n",
              "   ... Longitude Latitude Flights GridFins Reused  Legs LandingPad Block  \\\n",
              "0  ...      None     None    None     None   None  None       None  None   \n",
              "1  ...      None     None    None     None   None  None       None  None   \n",
              "2  ...      None     None    None     None   None  None       None  None   \n",
              "3  ...      None     None    None     None   None  None       None  None   \n",
              "4  ...      None     None    None     None   None  None       None  None   \n",
              "\n",
              "  ReusedCount Serial  \n",
              "0        None   None  \n",
              "1        None   None  \n",
              "2        None   None  \n",
              "3        None   None  \n",
              "4        None   None  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb7d3643-1106-466b-8bf5-dab31ab2fe85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight No.</th>\n",
              "      <th>FlightNumber</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Launch site</th>\n",
              "      <th>LaunchSite</th>\n",
              "      <th>Payload</th>\n",
              "      <th>Orbit</th>\n",
              "      <th>Customer</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>...</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Flights</th>\n",
              "      <th>GridFins</th>\n",
              "      <th>Reused</th>\n",
              "      <th>Legs</th>\n",
              "      <th>LandingPad</th>\n",
              "      <th>Block</th>\n",
              "      <th>ReusedCount</th>\n",
              "      <th>Serial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>January 3, 202314:56[17]</td>\n",
              "      <td>January 3, 202314:56[17]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Unknown[j]</td>\n",
              "      <td>Various</td>\n",
              "      <td>Success</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>January 10, 202304:50[23]</td>\n",
              "      <td>January 10, 202304:50[23]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>6,000 kg (13,000 lb)</td>\n",
              "      <td>OneWeb</td>\n",
              "      <td>Success</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>January 15, 202322:56[29]</td>\n",
              "      <td>January 15, 202322:56[29]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>~3,750 kg (8,270 lb)</td>\n",
              "      <td>USSF</td>\n",
              "      <td>Success</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>January 18, 202312:24[33]</td>\n",
              "      <td>January 18, 202312:24[33]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>4,352 kg (9,595 lb)</td>\n",
              "      <td>USSF</td>\n",
              "      <td>Success</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>January 19, 202315:43[39]</td>\n",
              "      <td>January 19, 202315:43[39]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>15,000 kg (33,000 lb)</td>\n",
              "      <td>SpaceX</td>\n",
              "      <td>Success</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb7d3643-1106-466b-8bf5-dab31ab2fe85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb7d3643-1106-466b-8bf5-dab31ab2fe85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb7d3643-1106-466b-8bf5-dab31ab2fe85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ea903fe-6fde-411e-b3fc-80cd0cc59828\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ea903fe-6fde-411e-b3fc-80cd0cc59828')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ea903fe-6fde-411e-b3fc-80cd0cc59828 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total launches scraped: 98\n",
            "\n",
            "All columns available from scraping:\n",
            "['Flight No.', 'FlightNumber', 'Date', 'Time', 'Launch site', 'LaunchSite', 'Payload', 'Orbit', 'Customer', 'Outcome', 'Launchoutcome', 'BoosterVersion', 'Version Booster', 'Booster landing', 'PayloadMass', 'Longitude', 'Latitude', 'Flights', 'GridFins', 'Reused', 'Legs', 'LandingPad', 'Block', 'ReusedCount', 'Serial']\n",
            "\n",
            "Data saved to spacex_scraped_launches.csv in Colab environment.\n",
            "You can download this file from the 'Files' tab (left sidebar) or using: from google.colab import files; files.download('spacex_scraped_launches.csv')\n",
            "\n",
            "Attempting to mount Google Drive for persistent storage...\n",
            "Mounted at /content/drive\n",
            "Data saved to Google Drive at: /content/drive/MyDrive/spacex_scraped_data/spacex_scraped_launches.csv\n"
          ]
        }
      ]
    }
  ]
}